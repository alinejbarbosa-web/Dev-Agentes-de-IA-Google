{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM0M3P5Tvf2bXPaF1LFCR+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alinejbarbosa-web/Dev-Agentes-de-IA-Google/blob/main/Agente_de_IA_Alura_09_09_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AULA 01"
      ],
      "metadata": {
        "id": "bi1EwgjUmppZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tP-vsromXE4-",
        "outputId": "b0d23da0-fe8d-4942-ff7c-c9b5ffe0e7ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain-google-genai google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTAR API KEY"
      ],
      "metadata": {
        "id": "C1DBFtKblz-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "Google_API_Key = userdata.get('Gemini_Api_Key')"
      ],
      "metadata": {
        "id": "b4E2XiHyXUhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CONECTAR COM GEMINI"
      ],
      "metadata": {
        "id": "OKTKdcRzmIpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ASBK = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.0,\n",
        "    api_key=Google_API_Key,\n",
        ")\n"
      ],
      "metadata": {
        "id": "azptbS8fXT_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "COLOCAR A CÉLULA PARA FUNCIONAR SOLICITANDO UMA RESPOSTA"
      ],
      "metadata": {
        "id": "YsNiPe7nqNRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp_test= ASBK.invoke (\"Quem é você?\")"
      ],
      "metadata": {
        "id": "TnMq5p1oqWVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "piQp-ArErCZH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "INVOKE PARA INVOCAR O MODELO QUE FIZEMOS ANTERIORMENTE (ALGO ACONTECEU APÓS EXECUTAR A CÉLULA, E DEPOIS DO PRINT SABEREMOS O QUE FOI FEITO)"
      ],
      "metadata": {
        "id": "Ka2TVuoqqwtn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(resp_test.content)"
      ],
      "metadata": {
        "id": "YxaCIU_Jq1ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resp_test)"
      ],
      "metadata": {
        "id": "VCjBMNOTrkiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SEM O .CONTENT ELE DÁ TUDO QUE PODERIA TER DE VARIÁVEL RELACIONADO A COMANDO, E COM O CONTENT É MAIS RESUMIDO"
      ],
      "metadata": {
        "id": "oj-dFQc5rm5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ASBK = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=1.0,\n",
        "    api_key=Google_API_Key\n",
        ")"
      ],
      "metadata": {
        "id": "Rn6cm0UZr6a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A TEMPERATURA FOI PARA 1.0 PARA DAR MAIS DETALHES NAS INFORMAÇÕES."
      ],
      "metadata": {
        "id": "Wi7J7eymuAd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resp_test= ASBK.invoke (\"Quem é você? Seja criativo\")\n",
        "print(resp_test.content)"
      ],
      "metadata": {
        "id": "KKJ29-vjsfY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MANTER TEMPERATURA 0.0 PARA SEGUIR A IMERSÃO"
      ],
      "metadata": {
        "id": "6nSwcFFmuHva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ASBK = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    temperature=0.0,\n",
        "    api_key=Google_API_Key\n",
        ")"
      ],
      "metadata": {
        "id": "RM-gvY0KthgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp_test= ASBK.invoke (\"Quem é você? Seja criativo\")\n",
        "print(resp_test.content)"
      ],
      "metadata": {
        "id": "T04ERcRNuN8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AULA 02"
      ],
      "metadata": {
        "id": "NagIDhROlFX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalar Bibliotecas\n",
        "Community tem várias integrações com recursos.\n",
        "Faiss faz busca semântica em que entende o significado e a intenção da pesquis.\n",
        "Langchain-text-splitters quebra o texto em vários pedaços.\n",
        "Pymupdf lê PDF.\n"
      ],
      "metadata": {
        "id": "PHQr7vIllPmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade langchain_community faiss-cpu langchain-text-splitters pymupdf"
      ],
      "metadata": {
        "id": "ZHlz4q4GubVV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Trazer os documentos da Empresa para o Colab fazendo upload na lasta ao lado deste comando. Toda vez que precisa, terá que fazer ipload, mas pode usar o Codigo da célula para pedir ao Gemini um comando que gere o upload automaticamente do Drive todas que vez que acessar o Colab."
      ],
      "metadata": {
        "id": "vGZggvtnoGsA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As bibliotecas foram instaladas no primeiro comando da AULA 02, agora serão importadas. Documentos serão lidos. Então, precisa salvar os docs que foram baixados. Cria a lista vazia para depois inserir os docs."
      ],
      "metadata": {
        "id": "Dj8viXpjo9zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "\n",
        "docs = []\n",
        "\n",
        "for n in Path(\"/content/\").glob(\"*.pdf\"):\n",
        "    try:\n",
        "        loader = PyMuPDFLoader(str(n))\n",
        "        docs.extend(loader.load())\n",
        "        print(f\"Carregado com sucesso arquivo {n.name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao carregar arquivo {n.name}: {e}\")\n",
        "\n",
        "print(f\"Total de documentos carregados: {len(docs)}\")"
      ],
      "metadata": {
        "id": "D2m-zC83oRAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=30)\n",
        "\n",
        "chunks = splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "gpCdC7y8oJ8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "id": "ZGFlV1d_r6GW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in chunks:\n",
        "    print(chunk)\n",
        "    print(\"------------------------------------\")"
      ],
      "metadata": {
        "id": "HxxQkLytsEFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model=\"models/gemini-embedding-001\",\n",
        "    google_api_key=Google_API_Key\n",
        ")"
      ],
      "metadata": {
        "id": "EGvF9Qb7srd0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tipo de busca e o parâmetro de busca (Threshold)"
      ],
      "metadata": {
        "id": "03sN6VjZ0PIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_type=\"similarity_score_threshold\",\n",
        "                                     search_kwargs={\"score_threshold\":0.3, \"k\": 4})"
      ],
      "metadata": {
        "id": "UKzUdM2Ns2Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "\n",
        "prompt_rag = ChatPromptTemplate.from_messages([\n",
        "    (\"system\",\n",
        "     \"Você é um Assistente de Políticas Internas (RH/IT) da empresa Carraro Desenvolvimento. \"\n",
        "     \"Responda SOMENTE com base no contexto fornecido. \"\n",
        "     \"Se não houver base suficiente, responda apenas 'Não sei'.\"),\n",
        "\n",
        "    (\"human\", \"Pergunta: {input}\\n\\nContexto:\\n{context}\")\n",
        "])\n",
        "\n",
        "document_chain = create_stuff_documents_chain(ASBK, prompt_rag)"
      ],
      "metadata": {
        "id": "jyJTEuUJs78k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Formatadores\n",
        "import re, pathlib\n",
        "from typing import List, Dict\n",
        "\n",
        "def _clean_text(s: str) -> str:\n",
        "    return re.sub(r\"\\s+\", \" \", s or \"\").strip()\n",
        "\n",
        "def extrair_trecho(texto: str, query: str, janela: int = 240) -> str:\n",
        "    txt = _clean_text(texto)\n",
        "    termos = [t.lower() for t in re.findall(r\"\\w+\", query or \"\") if len(t) >= 4]\n",
        "    pos = -1\n",
        "    for t in termos:\n",
        "        pos = txt.lower().find(t)\n",
        "        if pos != -1: break\n",
        "    if pos == -1: pos = 0\n",
        "    ini, fim = max(0, pos - janela // 2), min(len(txt), pos + janela // 2)\n",
        "    return txt[ini:fim]\n",
        "\n",
        "def formatar_citacoes(docs_rel: List, query: str) -> List[Dict]:\n",
        "    cites, seen = [], set()\n",
        "    for d in docs_rel:\n",
        "        src = pathlib.Path(d.metadata.get(\"source\",\"\")).name\n",
        "        page = int(d.metadata.get(\"page\", 0)) + 1\n",
        "        key = (src, page)\n",
        "        if key in seen:\n",
        "            continue\n",
        "        seen.add(key)\n",
        "        cites.append({\"documento\": src, \"pagina\": page, \"trecho\": extrair_trecho(d.page_content, query)})\n",
        "    return cites[:3]"
      ],
      "metadata": {
        "id": "jBHu-cFqtX9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perguntar_politica_RAG(pergunta: str) -> Dict:\n",
        "    docs_relacionados = retriever.invoke(pergunta)\n",
        "\n",
        "    if not docs_relacionados:\n",
        "        return {\"answer\": \"Não sei.\",\n",
        "                \"citacoes\": [],\n",
        "                \"contexto_encontrado\": False}\n",
        "\n",
        "    answer = document_chain.invoke({\"input\": pergunta,\n",
        "                                    \"context\": docs_relacionados})\n",
        "\n",
        "    txt = (answer or \"\").strip()\n",
        "\n",
        "    if txt.rstrip(\".!?\") == \"Não sei\":\n",
        "        return {\"answer\": \"Não sei.\",\n",
        "                \"citacoes\": [],\n",
        "                \"contexto_encontrado\": False}\n",
        "\n",
        "    return {\"answer\": txt,\n",
        "            \"citacoes\": formatar_citacoes(docs_relacionados, pergunta),\n",
        "            \"contexto_encontrado\": True}"
      ],
      "metadata": {
        "id": "b-5eCxGRt7EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testes = [\"Posso reembolsar a internet?\",\n",
        "          \"Quero mais 5 dias de trabalho remoto. Como faço?\",\n",
        "          \"Posso reembolsar cursos ou treinamentos da Alura?\",\n",
        "          \"Quantas capivaras tem no Rio Pinheiros?\"]"
      ],
      "metadata": {
        "id": "Kxa8NX63t9hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for msg_teste in testes:\n",
        "    resposta = perguntar_politica_RAG(msg_teste)\n",
        "    print(f\"PERGUNTA: {msg_teste}\")\n",
        "    print(f\"RESPOSTA: {resposta['answer']}\")\n",
        "    if resposta['contexto_encontrado']:\n",
        "        print(\"CITAÇÕES:\")\n",
        "        for c in resposta['citacoes']:\n",
        "            print(f\" - Documento: {c['documento']}, Página: {c['pagina']}\")\n",
        "            print(f\"   Trecho: {c['trecho']}\")\n",
        "        print(\"------------------------------------\")"
      ],
      "metadata": {
        "id": "yatN-EhRuDSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}